{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk"
      ],
      "metadata": {
        "id": "agTRVR3PE-Wu"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "l1Jer2htKMu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Reviews.csv\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0PI0LjsIaS9",
        "outputId": "8b6eecba-a7b2-4c16-f2e5-e513cd6f726e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = df['Text'].dropna().head(10000)"
      ],
      "metadata": {
        "id": "uEZ2LWjPIaVm"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    return text\n",
        "reviews = reviews.apply(preprocess)"
      ],
      "metadata": {
        "id": "9s9zRmRtIaYk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def tokenize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w for w in tokens if w.isalpha() and w not in stop_words]\n",
        "    return tokens\n",
        "tokenized_reviews = reviews.apply(tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e5XmPnFIabe",
        "outputId": "f5a3bec2-b1c1-43c6-f65d-31bc70126856"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pos_tagged = tokenized_reviews.apply(pos_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15WCyMkIIaec",
        "outputId": "a3dbee50-51ac-4675-f608-36612cd0557c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "ner = pos_tagged.apply(ne_chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Fcr35RIahW",
        "outputId": "01dd6cbf-2c61-4eef-e86f-a89555a00d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJ-H0Q8tIakf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}